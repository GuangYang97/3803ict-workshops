{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "145fb112-c16b-4f07-9bc1-fa5843b50910",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "a99b2434-e26b-49b4-9666-a5b464f930a6",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap = \"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab632b5-ab4c-4886-f388-682915da9f69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes = 10)\n",
        "y_test_cat = to_categorical(y_test, num_classes = 10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3775a623-31cd-414d-f9e7-3c3cb85e786a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               48120     \n",
            "                                                                 \n",
            " F6 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation='relu', name='C5'))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation='relu', name='F6'))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "9626efa5-64de-4a54-834a-77f3dc3b9d22",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 13s 32ms/step - loss: 1.9432 - accuracy: 0.4168 - val_loss: 1.1965 - val_accuracy: 0.6369\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.8997 - accuracy: 0.6774 - val_loss: 0.7419 - val_accuracy: 0.7307\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.6584 - accuracy: 0.7557 - val_loss: 0.6204 - val_accuracy: 0.7680\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5680 - accuracy: 0.7873 - val_loss: 0.5532 - val_accuracy: 0.7935\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5184 - accuracy: 0.8064 - val_loss: 0.5216 - val_accuracy: 0.8030\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.4862 - accuracy: 0.8193 - val_loss: 0.4976 - val_accuracy: 0.8138\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.4629 - accuracy: 0.8283 - val_loss: 0.4766 - val_accuracy: 0.8266\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.4450 - accuracy: 0.8366 - val_loss: 0.4701 - val_accuracy: 0.8304\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.4280 - accuracy: 0.8442 - val_loss: 0.4428 - val_accuracy: 0.8372\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.4170 - accuracy: 0.8482 - val_loss: 0.4346 - val_accuracy: 0.8415\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.4027 - accuracy: 0.8536 - val_loss: 0.4248 - val_accuracy: 0.8466\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3940 - accuracy: 0.8576 - val_loss: 0.4108 - val_accuracy: 0.8512\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3831 - accuracy: 0.8624 - val_loss: 0.4080 - val_accuracy: 0.8543\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3731 - accuracy: 0.8666 - val_loss: 0.4009 - val_accuracy: 0.8534\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3690 - accuracy: 0.8668 - val_loss: 0.4007 - val_accuracy: 0.8493\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3633 - accuracy: 0.8691 - val_loss: 0.3878 - val_accuracy: 0.8594\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3535 - accuracy: 0.8729 - val_loss: 0.3860 - val_accuracy: 0.8602\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3509 - accuracy: 0.8730 - val_loss: 0.3809 - val_accuracy: 0.8610\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3430 - accuracy: 0.8766 - val_loss: 0.3866 - val_accuracy: 0.8596\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3381 - accuracy: 0.8789 - val_loss: 0.3723 - val_accuracy: 0.8626\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3338 - accuracy: 0.8803 - val_loss: 0.3701 - val_accuracy: 0.8659\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3299 - accuracy: 0.8818 - val_loss: 0.3626 - val_accuracy: 0.8689\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3249 - accuracy: 0.8833 - val_loss: 0.3592 - val_accuracy: 0.8694\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3209 - accuracy: 0.8850 - val_loss: 0.3560 - val_accuracy: 0.8712\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3177 - accuracy: 0.8857 - val_loss: 0.3520 - val_accuracy: 0.8739\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3158 - accuracy: 0.8860 - val_loss: 0.3471 - val_accuracy: 0.8739\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3103 - accuracy: 0.8880 - val_loss: 0.3563 - val_accuracy: 0.8719\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3138 - accuracy: 0.8868 - val_loss: 0.3435 - val_accuracy: 0.8758\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3034 - accuracy: 0.8909 - val_loss: 0.3413 - val_accuracy: 0.8776\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3007 - accuracy: 0.8915 - val_loss: 0.3365 - val_accuracy: 0.8789\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2990 - accuracy: 0.8922 - val_loss: 0.3433 - val_accuracy: 0.8721\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2971 - accuracy: 0.8917 - val_loss: 0.3359 - val_accuracy: 0.8801\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2977 - accuracy: 0.8915 - val_loss: 0.3476 - val_accuracy: 0.8740\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2962 - accuracy: 0.8927 - val_loss: 0.3301 - val_accuracy: 0.8812\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2894 - accuracy: 0.8955 - val_loss: 0.3346 - val_accuracy: 0.8793\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2851 - accuracy: 0.8974 - val_loss: 0.3309 - val_accuracy: 0.8797\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2846 - accuracy: 0.8974 - val_loss: 0.3335 - val_accuracy: 0.8777\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2843 - accuracy: 0.8978 - val_loss: 0.3234 - val_accuracy: 0.8842\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2802 - accuracy: 0.8989 - val_loss: 0.3319 - val_accuracy: 0.8830\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2802 - accuracy: 0.8989 - val_loss: 0.3223 - val_accuracy: 0.8849\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2737 - accuracy: 0.9008 - val_loss: 0.3189 - val_accuracy: 0.8853\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2729 - accuracy: 0.9010 - val_loss: 0.3292 - val_accuracy: 0.8819\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2720 - accuracy: 0.9016 - val_loss: 0.3289 - val_accuracy: 0.8802\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2709 - accuracy: 0.9012 - val_loss: 0.3206 - val_accuracy: 0.8844\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2667 - accuracy: 0.9036 - val_loss: 0.3134 - val_accuracy: 0.8885\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2653 - accuracy: 0.9039 - val_loss: 0.3128 - val_accuracy: 0.8885\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2641 - accuracy: 0.9043 - val_loss: 0.3127 - val_accuracy: 0.8887\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2627 - accuracy: 0.9043 - val_loss: 0.3127 - val_accuracy: 0.8868\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2586 - accuracy: 0.9067 - val_loss: 0.3195 - val_accuracy: 0.8834\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2617 - accuracy: 0.9044 - val_loss: 0.3313 - val_accuracy: 0.8781\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2593 - accuracy: 0.9061 - val_loss: 0.3223 - val_accuracy: 0.8802\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2596 - accuracy: 0.9052 - val_loss: 0.3082 - val_accuracy: 0.8882\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2523 - accuracy: 0.9082 - val_loss: 0.3167 - val_accuracy: 0.8844\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2547 - accuracy: 0.9065 - val_loss: 0.3091 - val_accuracy: 0.8891\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2495 - accuracy: 0.9092 - val_loss: 0.3067 - val_accuracy: 0.8915\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2517 - accuracy: 0.9087 - val_loss: 0.3139 - val_accuracy: 0.8861\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2494 - accuracy: 0.9091 - val_loss: 0.3087 - val_accuracy: 0.8903\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.9092 - val_loss: 0.3074 - val_accuracy: 0.8896\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2458 - accuracy: 0.9104 - val_loss: 0.3035 - val_accuracy: 0.8914\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2490 - accuracy: 0.9093 - val_loss: 0.3144 - val_accuracy: 0.8846\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2414 - accuracy: 0.9126 - val_loss: 0.3134 - val_accuracy: 0.8857\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2425 - accuracy: 0.9105 - val_loss: 0.3030 - val_accuracy: 0.8926\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2404 - accuracy: 0.9113 - val_loss: 0.3079 - val_accuracy: 0.8873\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2418 - accuracy: 0.9116 - val_loss: 0.3075 - val_accuracy: 0.8877\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2393 - accuracy: 0.9132 - val_loss: 0.3120 - val_accuracy: 0.8856\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2412 - accuracy: 0.9115 - val_loss: 0.3068 - val_accuracy: 0.8899\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2355 - accuracy: 0.9143 - val_loss: 0.3014 - val_accuracy: 0.8916\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2338 - accuracy: 0.9146 - val_loss: 0.2970 - val_accuracy: 0.8929\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2323 - accuracy: 0.9164 - val_loss: 0.3062 - val_accuracy: 0.8912\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2308 - accuracy: 0.9159 - val_loss: 0.3063 - val_accuracy: 0.8871\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2313 - accuracy: 0.9154 - val_loss: 0.3038 - val_accuracy: 0.8898\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2266 - accuracy: 0.9174 - val_loss: 0.3018 - val_accuracy: 0.8907\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2290 - accuracy: 0.9166 - val_loss: 0.3103 - val_accuracy: 0.8875\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2283 - accuracy: 0.9162 - val_loss: 0.3049 - val_accuracy: 0.8915\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2265 - accuracy: 0.9177 - val_loss: 0.3033 - val_accuracy: 0.8908\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2260 - accuracy: 0.9171 - val_loss: 0.2974 - val_accuracy: 0.8919\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2245 - accuracy: 0.9182 - val_loss: 0.2956 - val_accuracy: 0.8936\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2224 - accuracy: 0.9187 - val_loss: 0.2982 - val_accuracy: 0.8950\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2224 - accuracy: 0.9180 - val_loss: 0.2979 - val_accuracy: 0.8942\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2205 - accuracy: 0.9186 - val_loss: 0.3005 - val_accuracy: 0.8914\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2227 - accuracy: 0.9193 - val_loss: 0.2981 - val_accuracy: 0.8921\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2177 - accuracy: 0.9196 - val_loss: 0.2995 - val_accuracy: 0.8938\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2177 - accuracy: 0.9201 - val_loss: 0.2990 - val_accuracy: 0.8952\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2169 - accuracy: 0.9212 - val_loss: 0.2963 - val_accuracy: 0.8959\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2155 - accuracy: 0.9209 - val_loss: 0.2970 - val_accuracy: 0.8957\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2151 - accuracy: 0.9213 - val_loss: 0.2982 - val_accuracy: 0.8935\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2179 - accuracy: 0.9200 - val_loss: 0.2950 - val_accuracy: 0.8941\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2100 - accuracy: 0.9230 - val_loss: 0.2929 - val_accuracy: 0.8946\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2083 - accuracy: 0.9244 - val_loss: 0.3021 - val_accuracy: 0.8948\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2143 - accuracy: 0.9215 - val_loss: 0.2987 - val_accuracy: 0.8918\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2113 - accuracy: 0.9222 - val_loss: 0.2928 - val_accuracy: 0.8986\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2070 - accuracy: 0.9239 - val_loss: 0.3007 - val_accuracy: 0.8937\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2081 - accuracy: 0.9233 - val_loss: 0.2925 - val_accuracy: 0.8959\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2078 - accuracy: 0.9229 - val_loss: 0.2981 - val_accuracy: 0.8921\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2096 - accuracy: 0.9231 - val_loss: 0.3062 - val_accuracy: 0.8913\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2073 - accuracy: 0.9236 - val_loss: 0.2900 - val_accuracy: 0.8987\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2010 - accuracy: 0.9271 - val_loss: 0.2938 - val_accuracy: 0.8941\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2031 - accuracy: 0.9259 - val_loss: 0.2939 - val_accuracy: 0.8968\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2056 - accuracy: 0.9244 - val_loss: 0.2945 - val_accuracy: 0.8960\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.2020 - accuracy: 0.9252 - val_loss: 0.2976 - val_accuracy: 0.8949\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd03d071bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "ba45641b-b8d6-4b01-ecf5-035888bd0151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 1s 5ms/step\n",
            "10/10 [==============================] - 0s 13ms/step\n",
            "accuracy on train with CNN: 0.9259333333333334\n",
            "accuracy on test with CNN: 0.8949\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = 1024).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size = 1024).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "21930d7a-4849-4cc8-84d1-058cb006fb06",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-5da9cbf7d7d8>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 55ms/step - loss: 0.4571 - accuracy: 0.8577 - val_loss: 0.3318 - val_accuracy: 0.8805\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2906 - accuracy: 0.8945 - val_loss: 0.3146 - val_accuracy: 0.8856\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2725 - accuracy: 0.9000 - val_loss: 0.3005 - val_accuracy: 0.8934\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2614 - accuracy: 0.9044 - val_loss: 0.2982 - val_accuracy: 0.8949\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2557 - accuracy: 0.9070 - val_loss: 0.2933 - val_accuracy: 0.8934\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2511 - accuracy: 0.9081 - val_loss: 0.2981 - val_accuracy: 0.8935\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2476 - accuracy: 0.9088 - val_loss: 0.2898 - val_accuracy: 0.8965\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2432 - accuracy: 0.9110 - val_loss: 0.2932 - val_accuracy: 0.8965\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 4s 64ms/step - loss: 0.2427 - accuracy: 0.9104 - val_loss: 0.2858 - val_accuracy: 0.8966\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2381 - accuracy: 0.9132 - val_loss: 0.2969 - val_accuracy: 0.8946\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2367 - accuracy: 0.9128 - val_loss: 0.2920 - val_accuracy: 0.8956\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 4s 60ms/step - loss: 0.2361 - accuracy: 0.9134 - val_loss: 0.2904 - val_accuracy: 0.8952\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2323 - accuracy: 0.9141 - val_loss: 0.2943 - val_accuracy: 0.8935\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2299 - accuracy: 0.9142 - val_loss: 0.2903 - val_accuracy: 0.8954\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2289 - accuracy: 0.9164 - val_loss: 0.2871 - val_accuracy: 0.8977\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2259 - accuracy: 0.9166 - val_loss: 0.2867 - val_accuracy: 0.8977\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2263 - accuracy: 0.9169 - val_loss: 0.2904 - val_accuracy: 0.8989\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2249 - accuracy: 0.9165 - val_loss: 0.2852 - val_accuracy: 0.8987\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 4s 68ms/step - loss: 0.2206 - accuracy: 0.9195 - val_loss: 0.2804 - val_accuracy: 0.9002\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2191 - accuracy: 0.9201 - val_loss: 0.3055 - val_accuracy: 0.8902\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2209 - accuracy: 0.9185 - val_loss: 0.2841 - val_accuracy: 0.8968\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 4s 69ms/step - loss: 0.2177 - accuracy: 0.9201 - val_loss: 0.2800 - val_accuracy: 0.9018\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2160 - accuracy: 0.9211 - val_loss: 0.2840 - val_accuracy: 0.8986\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 3s 50ms/step - loss: 0.2185 - accuracy: 0.9193 - val_loss: 0.2870 - val_accuracy: 0.8971\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 4s 60ms/step - loss: 0.2155 - accuracy: 0.9206 - val_loss: 0.2782 - val_accuracy: 0.8996\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2128 - accuracy: 0.9205 - val_loss: 0.2811 - val_accuracy: 0.8997\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2115 - accuracy: 0.9219 - val_loss: 0.2835 - val_accuracy: 0.8979\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2092 - accuracy: 0.9226 - val_loss: 0.2790 - val_accuracy: 0.9003\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2061 - accuracy: 0.9232 - val_loss: 0.2821 - val_accuracy: 0.9003\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2083 - accuracy: 0.9229 - val_loss: 0.2822 - val_accuracy: 0.8984\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2043 - accuracy: 0.9241 - val_loss: 0.2842 - val_accuracy: 0.8962\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2047 - accuracy: 0.9242 - val_loss: 0.2817 - val_accuracy: 0.9001\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2023 - accuracy: 0.9255 - val_loss: 0.2878 - val_accuracy: 0.8986\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2025 - accuracy: 0.9244 - val_loss: 0.2836 - val_accuracy: 0.8980\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.1981 - accuracy: 0.9272 - val_loss: 0.2813 - val_accuracy: 0.9022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf7f37bb50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "0d4bbe0a-32c1-40d3-d35e-79fff0167d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "accuracy on train with NN: 0.93325\n",
            "accuracy on test with NN: 0.9022\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = 1024).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size = 1024).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}